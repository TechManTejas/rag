
# Retrieval-Augmented Generation (RAG) System

## ğŸ“Œ Overview

This project implements a minimal RAG (Retrieval-Augmented Generation) pipeline using:

-   **Streamlit** for the user interface
    
-   **SentenceTransformers** for generating embeddings
    
-   **FAISS** for similarity search
    
-   **Gemini** (or another LLM) for final answer generation
    

## ğŸ” System Workflow (High-Level)

```text
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                  SYSTEM WORKFLOW                    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                          User Inputs Text Chunks (Documents)
                                       â”‚
                                       â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ SentenceTransformer Model   â”‚
                         â”‚  (Embeds each chunk)        â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                          Produces Embeddings (Vectors)
                                       â”‚
                                       â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚   FAISS Indexing   â”‚
                            â”‚  (Vector Database) â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       
                                       
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  User Query (e.g. question) â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                          Query is embedded (vectorized)
                                       â”‚
                                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Vector Similarity Search (FAISS) â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                      Returns Top-K Most Relevant Chunks
                                       â”‚
                                       â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Language Model (e.g. Gemini)â”‚
                         â”‚ Generates Final Response    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

----------

## ğŸ§  Example Walkthrough

### 1. Input Chunks

```python
chunks: List[str] = [
    "RAG stands for Retrieval-Augmented Generation.",
    "It improves language model accuracy by grounding answers in facts.",
    "We use FAISS to search relevant chunks.",
    "Gemini generates the final answer."
]

```

### 2. Generate Embeddings

Each chunk is converted to a 384-dimensional vector.

```python
embeddings: List[List[float]] = [
    [0.12, -0.03, ..., 0.45],  # Embedding for chunk 1
    [0.11, -0.05, ..., 0.42],
    [0.08, -0.06, ..., 0.33],
    [0.10, -0.02, ..., 0.29],
]

```

### 3. Store in FAISS

FAISS index stores vectors for fast similarity search.

```text
FAISS Index (L2 Distance)
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID â”‚ Vector                     â”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0  â”‚ [0.12, -0.03, ..., 0.45]   â”‚
â”‚ 1  â”‚ [0.11, -0.05, ..., 0.42]   â”‚
â”‚ 2  â”‚ [0.08, -0.06, ..., 0.33]   â”‚
â”‚ 3  â”‚ [0.10, -0.02, ..., 0.29]   â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

### 4. Query Time!

```python
query = "What is RAG?"
query_embedding = embed_text([query])[0]  # [0.13, -0.04, ..., 0.44]

```

### 5. Search Top-K

```text
I = [[0, 1, 2]]  # Indices of top-3 closest vectors

```

### 6. Final Retrieved Chunks

```python
[
    "RAG stands for Retrieval-Augmented Generation.",
    "It improves language model accuracy by grounding answers in facts.",
    "We use FAISS to search relevant chunks."
]

```

## âœ… How to Run

```bash
pip install -r requirements.txt
streamlit run app.py

```
    

## â¤ï¸ Credits

-   [SentenceTransformers](https://www.sbert.net/)
    
-   [FAISS](https://github.com/facebookresearch/faiss)
    
-   [Streamlit](https://streamlit.io/)